{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##DEPENDENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pdfplumber\n",
    "%pip install groq\n",
    "%pip install --upgrade tiktoken\n",
    "%pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TABLE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = []\n",
    "extracted_tables = []\n",
    "\n",
    "with pdfplumber.open(\"Syndicated Loan.pdf\") as pdf:\n",
    "    for pg_number in range(len(pdf.pages)):\n",
    "        page = pdf.pages[pg_number]\n",
    "        tables = page.find_tables()\n",
    "        table_bboxes = [i.bbox for i in tables]\n",
    "        tables = [{'table': i.extract(), 'doctop': i.bbox[1]} for i in tables]\n",
    "        non_table_words = [word for word in page.extract_words() if not any(\n",
    "            [check_bboxes(word, table_bbox) for table_bbox in table_bboxes])]\n",
    "        \n",
    "        if len(tables) > 0 and len(non_table_words) > 0:\n",
    "            extracted_tables = tables\n",
    "            extracted_text = non_table_words  \n",
    "        elif len(tables) > 0:\n",
    "            extracted_tables = tables\n",
    "        elif len(non_table_words) > 0:\n",
    "            extracted_text.append(' '.join([i['text'] for i in non_table_words]))    \n",
    "            \n",
    "def check_bboxes(word, table_bbox):\n",
    "    \"\"\"\n",
    "    Check whether word is inside a table bbox.\n",
    "    \"\"\"\n",
    "    l = word['x0'], word['top'], word['x1'], word['bottom']\n",
    "    r = table_bbox\n",
    "    return l[0] > r[0] and l[1] > r[1] and l[2] < r[2] and l[3] < r[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the required_schema variable to include the \"bank_name\" property outside the \"items\" object\n",
    "required_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"bank_name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Name of the company to which pdf belong to\"\n",
    "        },\n",
    "        \"data\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Name of the lender\"\n",
    "                    },\n",
    "                    \"term_loan_commitment\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A term loan commitment is a lender's obligation to contribute their portion of the term loan to the borrower\"\n",
    "                    },\n",
    "                    \"total_commitment\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Total commitment of the lender to the project\"\n",
    "                    },\n",
    "                    \"percentage\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Percentage of the total commitment of the lender to the project\"\n",
    "                    },\n",
    "                    \"currency\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Currency of the commitment amount\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"name\",\n",
    "                    \"term_loan_commitment\",\n",
    "                    \"total_commitment\",\n",
    "                    \"percentage\",\n",
    "                    \"currency\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"bank_name\", \"data\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TOKEN SIZE CALCULATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def encoding_getter(encoding_type: str):\n",
    "    \"\"\"\n",
    "    Returns the appropriate encoding based on the given encoding type (either an encoding string or a model name).\n",
    "    \"\"\"\n",
    "    if \"k_base\" in encoding_type:\n",
    "        return tiktoken.get_encoding(encoding_type)\n",
    "    else:\n",
    "        return tiktoken.encoding_for_model(encoding_type)\n",
    "\n",
    "def tokenizer(string: str, encoding_type: str) -> list:\n",
    "    \"\"\"\n",
    "    Returns the tokens in a text string using the specified encoding.\n",
    "    \"\"\"\n",
    "    encoding = encoding_getter(encoding_type)\n",
    "    tokens = encoding.encode(string)\n",
    "    return tokens\n",
    "\n",
    "def token_counter(string: str, encoding_type: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns the number of tokens in a text string using the specified encoding.\n",
    "    \"\"\"\n",
    "    num_tokens = len(tokenizer(string, encoding_type))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_token_size = token_counter(str(extracted_tables), \"gpt-3.5-turbo\")\n",
    "text_token_size = token_counter(str(extracted_text), \"gpt-3.5-turbo\")\n",
    "total_pdf_token_size = table_token_size + text_token_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3162"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_token_len = 4092\n",
    "schema_len = len(str(required_schema))\n",
    "total_allowed_len = total_token_len - (schema_len + total_pdf_token_size)\n",
    "\n",
    "total_allowed_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##PASSING SPLITTED DATA TO LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['text',\n",
       "  ['ABC Bank, Inc Syndicated Loan Split Up Bank wise Total Loan Amount : $40,000,000 Chase: $10,000,000 Bank of America: $3,000,000 Goldman Sachs Bank: $7,000,000 Truist Bank: $20,000,000']],\n",
       " []]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 0\n",
    "end = total_pdf_token_size+1\n",
    "\n",
    "context = []\n",
    "\n",
    "\n",
    "if pdf_context_len < total_allowed_len:\n",
    "    context.append([\"text\",extracted_text])\n",
    "    context.append(extracted_tables)\n",
    "else:\n",
    "    pass\n",
    "    #chunk it and store\n",
    "    \n",
    "context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from groq import Groq\n",
    "client = Groq(\n",
    "  api_key=\"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\"\n",
    "    #  api_key=\"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\"\n",
    ")\n",
    "def get_model_response(system_prompt,user_prompt , schema ,model_name):  \n",
    "    chat_completion = client.chat.completions.create(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": str(system_prompt)\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Here is the text to parse: \" + str(user_prompt)\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            # \"content\": \"Here is the ouput JSON Schema , make sure you fill all the fields , the fields should not be empty or null  \\n [object Object]\" + str(schema)\n",
    "            \"content\": \"Here is the ouput JSON Schema , make sure you fill all the fields , the fields should not be empty or null  \\n [object Object]\" + str(schema) + \"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            # \"content\": \"Here is the ouput JSON Schema , make sure you fill all the fields , the fields should not be empty or null  \\n [object Object]\" + str(schema)\n",
    "            \"content\": \"\"\"Generate a chunk from the given table to embed and store it in a vector database such that each chunk contains the meaning for the table. Convert this table to a summary, then give the output as chunks to embed and store it in a vector database. Chunks in JSON format.\n",
    "                give output with markdown with chunk as heading \n",
    "                like \n",
    "                ##Chunk 1: \n",
    "                ##Chunk 2: \n",
    "                output : give only the chunks no extract line of text like Here is the output in markdown format with chunks as headings\n",
    "                Don't include bank_name in each chunk give it as one seperate chunks\n",
    "                \"\"\"\n",
    "\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Here is the perfectly correctly formatted JSON\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=8192,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    # response_format={\"type\": \"json_object\"},\n",
    "    stop=None,\n",
    ")  \n",
    "\n",
    "    return chat_completion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3-70B-8192\"\n",
    "# model_name = \"gemma-7b-it\"\n",
    "system_prompt = \"As a genius expert, your task is to understand the content and provide the parsed objects in json that match the following json_schema:\"\n",
    "user_prompt = \"Here is the text to parse:\" + str(context)\n",
    "output_formate = \"\"\n",
    "response = get_model_response(system_prompt,context , required_schema,model_name)\n",
    "\n",
    "\n",
    "\n",
    "llm_response_chunks = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Bank Name:\n",
      "{\"bank_name\": \"ABC Bank, Inc\"}\n",
      "\n",
      "## Chunk 1:\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"name\": \"Chase\",\n",
      "      \"term_loan_commitment\": \"$10,000,000\",\n",
      "      \"total_commitment\": \"$40,000,000\",\n",
      "      \"percentage\": \"25%\",\n",
      "      \"currency\": \"USD\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "## Chunk 2:\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"name\": \"Bank of America\",\n",
      "      \"term_loan_commitment\": \"$3,000,000\",\n",
      "      \"total_commitment\": \"$40,000,000\",\n",
      "      \"percentage\": \"7.5%\",\n",
      "      \"currency\": \"USD\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "## Chunk 3:\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"name\": \"Goldman Sachs Bank\",\n",
      "      \"term_loan_commitment\": \"$7,000,000\",\n",
      "      \"total_commitment\": \"$40,000,000\",\n",
      "      \"percentage\": \"17.5%\",\n",
      "      \"currency\": \"USD\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "## Chunk 4:\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"name\": \"Truist Bank\",\n",
      "      \"term_loan_commitment\": \"$20,000,000\",\n",
      "      \"total_commitment\": \"$40,000,000\",\n",
      "      \"percentage\": \"50%\",\n",
      "      \"currency\": \"USD\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(llm_response_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG (MARKDOWN CHUNKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='{\"bank_name\": \"ABC Bank, Inc\"}', metadata={'chunk': 'Bank Name:'}),\n",
       " Document(page_content='{\\n\"data\": [\\n{\\n\"name\": \"Chase\",\\n\"term_loan_commitment\": \"$10,000,000\",\\n\"total_commitment\": \"$40,000,000\",\\n\"percentage\": \"25%\",\\n\"currency\": \"USD\"\\n}\\n]\\n}', metadata={'chunk': 'Chunk 1:'}),\n",
       " Document(page_content='{\\n\"data\": [\\n{\\n\"name\": \"Bank of America\",\\n\"term_loan_commitment\": \"$3,000,000\",\\n\"total_commitment\": \"$40,000,000\",\\n\"percentage\": \"7.5%\",\\n\"currency\": \"USD\"\\n}\\n]\\n}', metadata={'chunk': 'Chunk 2:'}),\n",
       " Document(page_content='{\\n\"data\": [\\n{\\n\"name\": \"Goldman Sachs Bank\",\\n\"term_loan_commitment\": \"$7,000,000\",\\n\"total_commitment\": \"$40,000,000\",\\n\"percentage\": \"17.5%\",\\n\"currency\": \"USD\"\\n}\\n]\\n}', metadata={'chunk': 'Chunk 3:'}),\n",
       " Document(page_content='{\\n\"data\": [\\n{\\n\"name\": \"Truist Bank\",\\n\"term_loan_commitment\": \"$20,000,000\",\\n\"total_commitment\": \"$40,000,000\",\\n\"percentage\": \"50%\",\\n\"currency\": \"USD\"\\n}\\n]\\n}', metadata={'chunk': 'Chunk 4:'})]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "     (\"##\", \"chunk\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "mark_down_chunks = markdown_splitter.split_text(llm_response_chunks)\n",
    "mark_down_chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBEDDING TO CHROMA DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHROMA Embedding \n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "db = Chroma.from_documents(documents=mark_down_chunks, embedding=SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##RITRIVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_prompt_schema  = \"\"\"{{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{{\\\"bank_name\\\":{{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"Name of the company to which the PDF belongs\\\"}},\\\"data\\\":{{\\\"type\\\":\\\"array\\\",\\\"items\\\":{{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{{\\\"name\\\":{{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"Name of the lender\\\"}},\\\"term_loan_commitment\\\":{{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"A term loan commitment is a lender's obligation to contribute their portion of the term loan to the borrower\\\"}},\\\"total_commitment\\\":{{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"Total commitment of the lender to the project\\\"}},\\\"percentage\\\":{{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"Percentage of the total commitment of the lender to the project\\\"}},\\\"currency\\\":{{\\\"type\\\":\\\"string\\\",\\\"description\\\":\\\"Currency of the commitment amount\\\"}},\\\"required\\\":[\\\"name\\\",\\\"term_loan_commitment\\\",\\\"total_commitment\\\",\\\"percentage\\\",\\\"currency\\\"]}}}},\\\"required\\\":[\\\"bank_name\\\",\\\"data\\\"]}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"questions\"],\n",
    "    template=\"Extract all the following values :\" + llm_prompt_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting only the chunks that are similar to the query for llm to produce the output\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "llm = ChatGroq(temperature=0, groq_api_key=\"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\", model_name=\"llama3-70b-8192\")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "template = \"\"\" As a genius expert, your task is to understand the content and provide the parsed objects in json that match the following json_schema:\n",
    "        give json for only asked question\n",
    "        Here is the context :\n",
    "        context = {context}\n",
    "        Here is the output JSON Schema , make sure you fill all the fields , the fields should not be empty or null :\n",
    "        required schema {questions}\n",
    "         \"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "              {\"context\": retriever, \"questions\": RunnablePassthrough() }\n",
    "              | prompt\n",
    "              | llm\n",
    "              | StrOutputParser()\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rag_chain.invoke({'questions ' : llm_prompt_schema})  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context and JSON schema, I will parse the content and provide the output in JSON format. Here is the parsed output:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"bank_name\": \"ABC Bank, Inc\",\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"name\": \"Goldman Sachs Bank\",\n",
      "      \"term_loan_commitment\": \"$7,000,000\",\n",
      "      \"total_commitment\": \"$40,000,000\",\n",
      "      \"percentage\": \"17.5%\",\n",
      "      \"currency\": \"USD\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Bank of America\",\n",
      "      \"term_loan_commitment\": \"$3,000,000\",\n",
      "      \"total_commitment\": \"$40,000,000\",\n",
      "      \"percentage\": \"7.5%\",\n",
      "      \"currency\": \"USD\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Chase\",\n",
      "      \"term_loan_commitment\": \"$10,000,000\",\n",
      "      \"total_commitment\": \"$40,000,000\",\n",
      "      \"percentage\": \"25%\",\n",
      "      \"currency\": \"USD\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Truist Bank\",\n",
      "      \"term_loan_commitment\": \"$20,000,000\",\n",
      "      \"total_commitment\": \"$40,000,000\",\n",
      "      \"percentage\": \"50%\",\n",
      "      \"currency\": \"USD\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Note that I've combined the data from all the documents into a single JSON object, with the `bank_name` field populated from the last document, and the `data` array containing all the lender information from the other documents.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON schema written to file: ./output/Syndicated.json\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./outputs/Syndicated.json\"\n",
    "\n",
    "# Write JSON schema string to file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(res)\n",
    "\n",
    "print(\"JSON schema written to file:\", file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
